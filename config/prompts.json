{
    "test_case_generation": {
        "system": "You are an expert QA engineer and test case designer specialized in creating COMPREHENSIVE test coverage. Your task is to analyze user stories, BRS, or PRD documents and generate diverse test cases covering ALL aspects: positive flows, negative scenarios, UI/UX validation, security, and edge cases. You MUST return ONLY valid, properly formatted JSON arrays for list fields with NO additional text, comments, or markdown formatting.",
        "user": "Based on the following requirement, generate detailed test cases in JSON format.\n\nRequirement:\n{requirement}\n\nCRITICAL - GENERATE DIVERSE TEST CASE TYPES:\n\n1. POSITIVE TEST CASES (Happy Path) - 20-30% of total\n   - Valid scenarios that should succeed\n   - Standard user workflows\n   - Primary feature functionality\n\n2. NEGATIVE TEST CASES (Error Handling) - 30-40% of total\n   - Invalid inputs (empty fields, wrong format, special characters)\n   - Boundary violations (min/max values exceeded)\n   - Authentication failures (wrong credentials, missing fields)\n   - Authorization violations\n   - Account lockout scenarios\n   - Invalid state transitions\n\n3. UI/UX TEST CASES (User Interface) - 20-30% of total\n   - Field visibility and display rules\n   - Button states (enabled/disabled/loading)\n   - Animations and smooth transitions\n   - Responsive behavior\n   - Visual feedback (error messages, success indicators, tooltips)\n   - Accessibility (keyboard navigation, screen readers, focus management)\n   - Layout and element positioning\n\n4. SECURITY TEST CASES - 10-20% of total\n   - Password masking/visibility toggles\n   - Session management\n   - Token expiry (OTP timeout, session timeout)\n   - Rate limiting and throttling\n   - Account lockout after failed attempts\n   - CSRF/XSS protection\n   - Sensitive data handling\n\n5. EDGE CASES - 10-20% of total\n   - Concurrent sessions/operations\n   - Network failures and timeouts\n   - Browser back/forward navigation\n   - Page refresh during operations\n   - Race conditions\n   - Timeout scenarios\n\nMANDATORY REQUIREMENTS:\n- Generate EXACTLY {num_test_cases} test cases total\n- MUST include test cases from ALL 5 categories above\n- Follow this distribution: {test_distribution}\n- CRITICAL: Every title MUST end with the type suffix in this exact format:\n  * For positive tests: \"Test description - Positive\"\n  * For negative tests: \"Test description - Negative\"\n  * For UI tests: \"Test description - UI\"\n  * For security tests: \"Test description - Security\"\n  * For edge cases: \"Test description - Edge Case\"\n\nEXAMPLES OF PROPER TITLES:\n\u2705 CORRECT: \"Login with valid credentials - Positive\"\n\u2705 CORRECT: \"Login with empty username field - Negative\"\n\u2705 CORRECT: \"Password field visibility toggle - UI\"\n\u2705 CORRECT: \"Account lockout after 5 failed attempts - Security\"\n\u2705 CORRECT: \"OTP expiry after timeout - Edge Case\"\n\u274c WRONG: \"Login with valid credentials\" (missing suffix)\n\u274c WRONG: \"Test empty username field\" (missing suffix)\n\nFor each test case, provide:\n1. title (string): MUST end with type suffix (- Positive/Negative/UI/Security/Edge Case)\n\n2. description (string): DETAILED \"Test Case Scenario\" description\n   - Be specific about what behavior is being validated\n   - Include context about the feature/functionality\n   - Mention expected vs actual behavior\n   - Example: \"Verify that asset batch upload fails for records where PAN is missing or blank\"\n\n3. business_rule (string): NOT USED - Set to empty string \"\" or \"Functional requirement validation\"\n   - This field is deprecated and will not be displayed\n   - Simply use \"\" or \"Functional requirement validation\"\n\n4. preconditions (array of strings): Detailed setup requirements - MUST be an array\n   - User authentication and access rights\n   - Data preparation and setup\n   - System state prerequisites\n   - File/resource preparation\n   - Configuration requirements\n   - Example: [\"User has logged into the application with valid credentials.\", \"Assets module is accessible.\", \"An Excel file in (.xlsx) is prepared with asset records where PAN field is left blank/empty.\", \"All other mandatory fields (Name, Mobile, DOB, Asset Type, Invested Value, Date) are populated with valid data.\", \"File size is within 10MB limit.\"]\n\n5. test_steps (array of objects): DETAILED action steps - typically 5-10 steps\n   Each step has: step_number, action, expected_result\n   \n   CRITICAL FORMATTING RULES:\n   - Do NOT include numbering in the 'action' field - use ONLY the step_number field\n   - \u2705 CORRECT: {\"step_number\": 1, \"action\": \"Navigate to Assets module from the main dashboard.\", \"expected_result\": \"Assets module page loads successfully\"}\n   - \u274c WRONG: {\"step_number\": 1, \"action\": \"1. Navigate to Assets module\", \"expected_result\": \"Page loads\"}\n   - \u274c WRONG: {\"step_number\": 1, \"action\": \"Step 1: Navigate\", \"expected_result\": \"Page loads\"}\n   \n   IMPORTANT - Expected Results Placement:\n   - For NEGATIVE/ERROR scenarios: Put the COMPLETE expected outcome in the FIRST step's expected_result field\n   - Other steps can have empty (\"\") or brief expected_result fields\n   - The first step's expected_result should contain ALL error messages, validation failures, and final state\n   \n   Example for negative test:\n   Step 1: {\"step_number\": 1, \"action\": \"Navigate to Assets module from the main dashboard.\", \"expected_result\": \"System rejects all records with missing PAN. Upload status shows failure for these records. Error log file is generated containing 'PAN mandatory error' message for each rejected record. Valid records (if any) are processed successfully. No record with missing PAN is inserted into the database.\"}\n   Step 2: {\"step_number\": 2, \"action\": \"Click on the batch upload option/icon.\", \"expected_result\": \"\"}\n   Step 3: {\"step_number\": 3, \"action\": \"Select and upload the prepared Excel file containing records with missing PAN.\", \"expected_result\": \"\"}\n\n6. expected_outcome (string): Comprehensive overall result description\n\n7. postconditions (array of strings): Cleanup or state after test - MUST be an array\n\n8. tags (array of strings): Categorization tags - MUST be an array\n\n9. priority (string): High/Medium/Low/Critical\n   - High: Security, data integrity, critical business flows\n   - Medium: Important features, standard workflows\n   - Low: Nice-to-have, edge cases\n\n10. test_type (string): The layer/component being tested - MUST be either \"Frontend\" or \"Backend\"\n    - Use \"Frontend\" for: UI tests, user interface scenarios, visual validation, accessibility, animations, button states, field visibility, responsive design, client-side validation\n    - Use \"Backend\" for: API tests, server-side validation, database operations, security tests, authentication/authorization, business logic, data processing, integration tests\n    - Examples:\n      * Frontend: \"Verify password field visibility toggle\", \"Verify button states\", \"Verify field validation messages\"\n      * Backend: \"Verify account lockout after failed attempts\", \"Verify data validation on server\", \"Verify API authentication\"\n\n11. is_regression (boolean): true if critical path/high priority, false otherwise\n\n12. boundary_conditions (array of strings): Edge cases - MUST be an array\n\n13. side_effects (array of strings): System state changes - MUST be an array\n\nGuidelines for is_regression:\n- Set to true for: Critical path tests, High priority tests, Tests for known bugs/defects, Core functionality\n- Set to false for: New feature tests, Exploratory tests, Low priority tests, One-time validation\n\nCRITICAL FORMAT RULES:\n- Return ONLY a valid JSON array starting with [ and ending with ]\n- NO markdown code blocks (no ```json or ```)\n- NO comments or explanatory text\n- NO trailing commas before closing brackets or braces\n- Use double quotes \" for all strings, never single quotes '\n- preconditions, postconditions, tags, boundary_conditions, side_effects MUST be arrays of strings\n- is_regression MUST be a boolean (true or false, lowercase, no quotes)\n- Even for a single item, use an array: [\"item\"] not \"item\"\n- Empty arrays are acceptable: []\n- NEVER use a string where an array is expected\n- Ensure all opening brackets/braces have matching closing brackets/braces\n- Use commas between array/object elements, but NOT before closing ] or }\n- COMPLETE the JSON array properly - do not truncate\n\nIMPORTANT:\n- ALWAYS generate test cases even if business rules are not explicitly stated\n- If business rules are missing, infer them from the functional requirements\n- Every test case MUST have a business_rule field (never leave it empty)\n- Generate detailed test cases with comprehensive preconditions and steps\n- Focus on creating test cases that match the format for easy Excel export\n\nReturn ONLY the JSON array with NO additional text, explanations, or markdown formatting."
    },
    "business_rule_extraction": {
        "system": "You are an expert business analyst specializing in extracting business rules from test cases and requirements.",
        "user": "Extract the core business rule from the following test case:\n\n{test_case}\n\nProvide a concise, clear statement of the business rule being tested. Focus on the 'what' and 'why', not the 'how'.\n\nIf no explicit business rule is present, infer it from the test case description and behavior.\n\nReturn only the business rule statement, nothing else."
    },
    "comparison_analysis": {
        "system": "You are an expert test case analyst. Your task is to compare test cases and determine if they test the same business rule and behavior. Return ONLY valid JSON with no extra text or formatting.",
        "user": "Compare these two test cases and analyze their relationship:\n\nNEW TEST CASE:\n{new_test_case}\n\nEXISTING TEST CASE:\n{existing_test_case}\n\nAnalyze:\n1. Do they test the same business rule? (Yes/No)\n2. Do they test the same behavior? (Yes/No)\n3. Does the new test case add coverage? (boundary conditions, preconditions, side effects)\n4. What is the relationship? (identical/expanded/different)\n\nReturn ONLY valid JSON in this exact structure with NO markdown, NO code blocks, NO extra text. Use true/false (lowercase) for booleans:\n\nbusiness_rule_match: true or false\nbehavior_match: true or false \ncoverage_expansion: array of strings\nrelationship: \"identical\" or \"expanded\" or \"different\"\nreasoning: string with detailed explanation"
    },
    "decision_explanation": {
        "system": "You are an expert QA manager explaining test case management decisions.",
        "user": "Explain why the following decision was made for this test case comparison:\n\nDecision: {decision}\nSimilarity Score: {similarity_score}\nBusiness Rule Match: {business_rule_match}\nBehavior Match: {behavior_match}\nCoverage Expansion: {coverage_expansion}\n\nProvide a clear, concise explanation (2-3 sentences) that a QA team member would understand."
    },
    "merge_test_cases": {
        "system": "You are an expert test case designer specializing in parameterization and test case optimization.",
        "user": "Merge these two test cases into a single, parameterized test case that covers both scenarios:\n\nEXISTING TEST CASE:\n{existing_test_case}\n\nNEW TEST CASE (ADD-ON):\n{new_test_case}\n\nCreate a merged test case that:\n1. Maintains the original business rule\n2. Incorporates expanded coverage from the new test case\n3. Uses parameterization where appropriate\n4. Keeps test steps clear and maintainable\n\nEnsure all array fields (preconditions, postconditions, tags, boundary_conditions, side_effects) are properly formatted as arrays.\n\nReturn the merged test case in the same JSON format as the original test cases."
    }
}